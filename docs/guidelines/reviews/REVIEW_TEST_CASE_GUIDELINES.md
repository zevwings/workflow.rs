# 测试用例检查指南

> 本文档定义了如何检查测试用例的覆盖情况、合理性和完整性，用于指导 AI 进行测试用例检查。

---

## 📋 目录

- [测试边界和范围](#-测试边界和范围)
- [检查目标](#-检查目标)
- [检查步骤](#-检查步骤)
- [检查内容](#-检查内容)
  - [1. 测试覆盖情况检查](#1-测试覆盖情况检查)
  - [2. 测试用例合理性检查](#2-测试用例合理性检查)
  - [3. 缺失测试用例检查](#3-缺失测试用例检查)
- [检查方法](#-检查方法)
- [检查报告格式](#-检查报告格式)
- [参考文档](#-参考文档)

---

## 🎯 测试边界和范围

> **核心原则**：我们应该测试自己的业务逻辑，而不是测试外部依赖和第三方库的实现。

### ✅ 需要测试的内容

#### 1. 业务逻辑层

测试我们自己实现的业务规则和处理逻辑：

- ✅ **业务规则实现**
  - 分支前缀处理（如 `feature/` + 分支名）
  - 合并策略选择（如根据配置选择 `--no-ff` 或 `--ff-only`）
  - 数据验证规则（如分支名称验证、配置验证）
  - 业务流程控制（如 PR 创建流程、日志工作流）

- ✅ **数据转换和处理**
  - JSON/TOML 数据解析后的转换
  - 数据格式化（如日期格式、标题生成）
  - 数据聚合和计算（如统计、汇总）

- ✅ **状态管理**
  - 状态转换逻辑（如 Git 仓库状态、工作树状态）
  - 状态解析（如 `WorktreeStatus` 结构体的正确性）
  - 状态验证（如检查是否有未提交的更改）

- ✅ **数据结构的正确性**
  - 自定义数据结构（如 `CommitInfo`、`WorktreeStatus`、`BranchInfo`）
  - 数据结构的序列化/反序列化
  - 数据结构的默认值和验证

#### 2. 错误处理逻辑

测试我们如何处理错误，而不是测试错误是否会发生：

- ✅ **异常情况处理**
  - 检查错误情况是否被正确捕获
  - 检查错误恢复机制是否正确
  - 检查失败后的清理逻辑

- ✅ **错误消息和上下文**
  - 检查错误消息是否清晰准确
  - 检查错误上下文是否完整（使用 `anyhow::Context`）
  - 检查错误类型是否正确传递

- ✅ **错误传播**
  - 检查错误是否正确向上传播
  - 检查错误转换是否正确（如将底层错误转换为业务错误）

#### 3. 边界条件

测试各种边界情况和特殊输入：

- ✅ **输入边界**
  - 空输入（空字符串、空数组、空配置）
  - 最大/最小值（长度限制、数值范围）
  - 特殊字符（Unicode、换行符、特殊符号）
  - 无效输入（格式错误、类型错误）

- ✅ **输出边界**
  - 空结果处理
  - 超大结果处理
  - 格式化输出的正确性

- ✅ **并发场景**
  - 并发执行的安全性
  - 资源竞争处理
  - 并发错误处理

#### 4. 集成逻辑

测试我们如何封装和使用外部依赖：

- ✅ **API 调用封装**
  - 参数构造和传递
  - 请求配置（headers、auth、timeout）
  - 响应处理和数据提取

- ✅ **数据解析和转换**
  - API 响应的解析
  - 数据映射到内部数据结构
  - 错误响应的处理

- ✅ **重试和容错机制**
  - 重试逻辑的正确性（指数退避、最大重试次数）
  - 可重试错误的判断
  - 重试失败的处理

### ❌ 不需要测试的内容

#### 1. 外部依赖和第三方库

**核心原则**：不要测试外部工具和库的实现，它们已经有自己的测试。

#### 判断依据

使用以下问题判断是否需要测试：

1. **这段代码是谁写的？**
   - ❌ 外部库/工具的作者 → 不需要测试
   - ✅ 我们自己的团队 → 需要测试

2. **这段代码在哪里维护？**
   - ❌ 在外部仓库（如 crates.io、GitHub、系统工具） → 不需要测试
   - ✅ 在我们的项目中 → 需要测试

3. **测试的目的是什么？**
   - ❌ 验证外部库是否按文档工作 → 不需要测试（信任外部库）
   - ✅ 验证我们的代码逻辑是否正确 → 需要测试

#### 不需要测试的典型场景

- ❌ **外部命令行工具的功能**
  - 例如：Git、Docker、npm 等命令的基本功能
  - 不要测试：命令本身是否正确执行
  - 应该测试：我们如何构建命令参数、如何解析命令输出

- ❌ **第三方库的 API 实现**
  - 例如：HTTP 客户端、数据库驱动、序列化库
  - 不要测试：库的内部实现和协议处理
  - 应该测试：我们如何配置和使用这些库

- ❌ **远程 API 服务的业务逻辑**
  - 例如：GitHub API、Jira API、云服务 API
  - 不要测试：API 是否返回正确的业务数据
  - 应该测试：我们如何调用 API、如何处理 API 响应

- ❌ **标准库和系统调用**
  - 例如：文件系统、进程管理、网络操作
  - 不要测试：标准库的正确性
  - 应该测试：我们的文件处理逻辑、错误处理

- ❌ **语言和框架的核心功能**
  - 例如：Rust 标准库、语言特性、编译器行为
  - 不要测试：语言本身的功能
  - 应该测试：我们使用这些功能的业务逻辑

#### 2. 测试策略

对于外部依赖，采用以下策略：

- ✅ **使用 Mock 和 Stub 隔离测试**
  - 使用 `mockito` Mock HTTP API
  - 使用测试工具模拟 Git 仓库状态
  - 使用 Stub 模拟外部依赖的返回值

- ✅ **测试我们的代码如何使用外部依赖**
  - 测试我们传递给外部依赖的参数是否正确
  - 测试我们如何处理外部依赖的返回值
  - 测试我们如何处理外部依赖的错误

- ✅ **测试边界和异常情况**
  - 测试外部依赖返回错误时的处理
  - 测试外部依赖返回异常数据时的处理
  - 测试外部依赖超时或不可用时的处理

### 📚 具体示例

#### 示例 1: Git 模块

**✅ 应该测试的**：

```rust
// ✅ 测试分支前缀处理逻辑（我们的业务逻辑）
#[test]
fn test_format_branch_name_with_prefix() {
    let result = format_branch_name("feature", "login");
    assert_eq!(result, "feature/login");
}

// ✅ 测试合并策略选择逻辑（我们的业务逻辑）
#[test]
fn test_merge_strategy_selection() {
    let strategy = determine_merge_strategy(true, false);
    assert_eq!(strategy, MergeStrategy::NoFastForward);
}

// ✅ 测试分支名称验证逻辑（我们的业务逻辑）
#[test]
fn test_validate_branch_name() {
    assert!(validate_branch_name("feature/login").is_ok());
    assert!(validate_branch_name("invalid//name").is_err());
    assert!(validate_branch_name("").is_err());
}

// ✅ 测试 Git 命令执行失败时的错误处理（我们的错误处理）
#[test]
fn test_branch_create_error_handling() {
    // 使用 Mock 模拟 Git 命令失败
    let result = GitBranch::create("invalid/name");
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("分支名称无效"));
}

// ✅ 测试 CommitInfo 数据结构解析（我们的数据处理）
#[test]
fn test_parse_commit_info() {
    let output = "abc123\nJohn Doe\n2024-01-01\nInitial commit";
    let info = CommitInfo::from_output(output).unwrap();
    assert_eq!(info.hash, "abc123");
    assert_eq!(info.author, "John Doe");
}
```

**❌ 不应该测试的**：

```rust
// ❌ 不要测试 Git 命令本身是否正确（这是 Git 的责任）
#[test]
fn test_git_branch_command_creates_branch() {
    // 这是在测试 Git 本身，而不是我们的代码
    Command::new("git").args(["branch", "test"]).status().unwrap();
    let output = Command::new("git").args(["branch", "--list", "test"]).output().unwrap();
    assert!(String::from_utf8_lossy(&output.stdout).contains("test"));
}

// ❌ 不要测试 Git 参数的功能（这是 Git 的责任）
#[test]
fn test_git_merge_ff_only_parameter() {
    // 这是在测试 Git 的 --ff-only 参数，而不是我们的代码
    Command::new("git").args(["merge", "--ff-only", "feature"]).status().unwrap();
}

// ❌ 不要测试 Git 的底层实现（这是 Git 的责任）
#[test]
fn test_git_internal_merge_algorithm() {
    // 这是在测试 Git 的合并算法，而不是我们的代码
}
```

#### 示例 2: HTTP 模块

**✅ 应该测试的**：

```rust
// ✅ 测试请求配置构建逻辑（我们的业务逻辑）
#[test]
fn test_build_request_with_auth() {
    let client = HttpClient::new();
    let request = client.request("https://api.example.com")
        .with_auth("token", "abc123")
        .build();

    assert!(request.headers().contains_key("Authorization"));
    assert_eq!(request.headers().get("Authorization").unwrap(), "Bearer abc123");
}

// ✅ 测试重试逻辑（我们的业务逻辑）
#[test]
fn test_retry_on_network_error() {
    let mut mock_server = mockito::Server::new();
    let mock = mock_server.mock("GET", "/api")
        .with_status(500)
        .expect(3)  // 应该重试 3 次
        .create();

    let result = HttpClient::new().get(&format!("{}/api", mock_server.url())).await;
    assert!(result.is_err());
    mock.assert();
}

// ✅ 测试响应数据解析（我们的业务逻辑）
#[test]
fn test_parse_api_response() {
    let json = r#"{"id": 123, "name": "test"}"#;
    let data: ApiResponse = serde_json::from_str(json).unwrap();
    assert_eq!(data.id, 123);
    assert_eq!(data.name, "test");
}
```

**❌ 不应该测试的**：

```rust
// ❌ 不要测试 reqwest 是否正确发送 HTTP 请求（这是 reqwest 的责任）
#[test]
fn test_reqwest_sends_http_request() {
    // 这是在测试 reqwest 库，而不是我们的代码
    let response = reqwest::blocking::get("https://httpbin.org/get").unwrap();
    assert_eq!(response.status(), 200);
}

// ❌ 不要测试 HTTP 协议的正确性（这是标准协议）
#[test]
fn test_http_protocol() {
    // 这是在测试 HTTP 协议，而不是我们的代码
}
```

#### 示例 3: Jira 模块

**✅ 应该测试的**：

```rust
// ✅ 测试 Jira API 请求构建（我们的业务逻辑）
#[test]
fn test_build_jira_search_request() {
    let query = build_jira_query("PROJECT-123");
    assert_eq!(query, "project = PROJECT AND key = PROJECT-123");
}

// ✅ 测试 Jira 响应数据转换（我们的业务逻辑）
#[test]
fn test_convert_jira_issue_to_internal_format() {
    let jira_issue = mock_jira_issue();
    let issue = Issue::from_jira_response(jira_issue);
    assert_eq!(issue.key, "PROJECT-123");
    assert_eq!(issue.summary, "Test Issue");
}

// ✅ 测试日志格式化（我们的业务逻辑）
#[test]
fn test_format_worklog() {
    let worklog = Worklog {
        time_spent: 3600,
        comment: "Fixed bug",
    };
    let formatted = format_worklog(&worklog);
    assert_eq!(formatted, "1h - Fixed bug");
}
```

**❌ 不应该测试的**：

```rust
// ❌ 不要测试 Jira API 本身的功能（这是 Jira 的责任）
#[test]
fn test_jira_api_returns_correct_issue() {
    // 这是在测试 Jira API，而不是我们的代码
    let issue = jira_client.get_issue("PROJECT-123").await.unwrap();
    assert_eq!(issue.fields.summary, "Expected Summary");
}

// ❌ 不要测试 Jira 的业务逻辑（这是 Jira 的责任）
#[test]
fn test_jira_calculates_time_tracking() {
    // 这是在测试 Jira 的时间跟踪逻辑，而不是我们的代码
}
```

### 🎯 测试边界总结

| 测试类型 | 应该测试 ✅ | 不应该测试 ❌ |
|---------|------------|--------------|
| **业务逻辑** | 我们的业务规则、数据转换、状态管理 | 外部工具的业务逻辑 |
| **错误处理** | 我们如何处理错误、错误消息、错误恢复 | 外部工具是否会产生错误 |
| **数据结构** | 我们的数据结构、序列化、验证 | 标准库的数据结构 |
| **API 集成** | 我们如何调用 API、处理响应、错误处理 | API 本身的实现和正确性 |
| **Git 操作** | 我们的 Git 封装、参数构建、结果解析 | Git 命令本身的功能 |
| **HTTP 请求** | 我们的请求配置、重试逻辑、响应处理 | HTTP 客户端库的实现 |

**关键原则**：**测试我们自己写的代码，信任外部依赖已经过充分测试。**

---

## 🎯 检查目标

检查测试用例的三个核心方面：

1. **测试覆盖情况**：检查哪些模块/功能已有测试，哪些缺失
2. **测试用例合理性**：检查现有测试是否合理、规范、有效
3. **缺失测试用例**：识别需要补充的测试用例

---

## 🚀 检查步骤

按照以下步骤依次完成检查：

### 第一步：收集测试信息

1. **扫描测试目录结构**
   - 列出 `tests/` 目录下的所有测试文件
   - 列出源代码中 `#[cfg(test)]` 模块的单元测试
   - 记录测试文件与源代码模块的对应关系

2. **扫描源代码结构**
   - 列出 `src/lib/` 目录下的所有模块
   - 列出 `src/commands/` 目录下的所有命令
   - 识别公共 API 和关键业务逻辑

3. **统计测试数据**
   - 统计测试文件数量
   - 统计测试用例数量（估算）
   - 统计单元测试模块数量

### 第二步：检查测试覆盖情况

1. **模块覆盖检查**
   - 检查每个 `lib/` 模块是否有对应的测试
   - 检查每个 `commands/` 命令是否有对应的测试
   - 标记已覆盖、部分覆盖、完全缺失的模块

2. **功能覆盖检查**
   - 检查每个模块的主要功能是否有测试
   - 检查公共函数是否有测试
   - 检查关键业务逻辑是否有测试

3. **覆盖率评估**
   - 估算总体覆盖率
   - 估算核心模块覆盖率
   - 估算工具模块覆盖率

### 第三步：检查测试用例合理性

1. **测试工具使用检查**
   - 检查是否使用了合适的测试工具（`rstest`、`pretty_assertions`、`insta`、`mockito` 等）
   - 检查测试工具使用是否规范

2. **测试结构检查**
   - 检查测试是否遵循 AAA 模式（Arrange-Act-Assert）
   - 检查测试组织是否合理（模块分组、命名规范）
   - 检查测试数据管理是否规范（fixtures、快照）

3. **测试内容检查**
   - 检查是否包含成功路径测试
   - 检查是否包含错误路径测试
   - 检查是否包含边界条件测试
   - 检查是否包含集成测试

### 第四步：识别缺失的测试用例

1. **缺失模块测试识别**
   - 识别完全没有测试的模块
   - 识别测试文件存在但为空的模块
   - 识别部分子模块缺少测试的情况

2. **缺失功能测试识别**
   - 识别主要功能缺少测试的情况
   - 识别公共函数缺少测试的情况
   - 识别关键业务逻辑缺少测试的情况

3. **缺失测试类型识别**
   - 识别缺少错误路径测试的情况
   - 识别缺少边界条件测试的情况
   - 识别缺少集成测试的情况

### 第五步：生成检查报告

根据检查结果生成结构化的检查报告。

**对应章节**：[检查报告格式](#-检查报告格式)

---

## 📝 检查内容

### 1. 测试覆盖情况检查

#### 1.1 模块覆盖检查

**检查项**：

- [ ] **已覆盖的模块**：列出所有有完整测试的模块
  - 检查测试文件是否存在
  - 检查测试文件是否包含实际测试用例
  - 检查测试是否覆盖主要功能

- [ ] **部分覆盖的模块**：列出测试不完整的模块
  - 检查测试文件是否存在但为空
  - 检查是否只覆盖了部分子模块
  - 检查是否只覆盖了部分功能

- [ ] **完全缺失的模块**：列出完全没有测试的模块
  - 检查是否有对应的测试文件
  - 检查是否有单元测试

**检查方法**：

1. 遍历 `src/lib/` 目录，列出所有模块
2. 检查 `tests/` 目录是否有对应的测试文件
3. 检查测试文件是否包含实际测试代码（不只是注释）
4. 检查源代码中是否有 `#[cfg(test)]` 模块

**示例输出**：

```markdown
#### Base 模块 (`lib/base/`)
- ✅ `base/llm_client.rs` - LLM 客户端测试
- ✅ `base/logger.rs` - 日志功能测试
- ⚠️ `base/http.rs` - 测试文件存在但为空
- ❌ `base/alias/config.rs` - 无测试文件
```

#### 1.2 功能覆盖检查

**检查项**：

- [ ] **公共函数覆盖**：检查公共函数是否有测试
  - 列出所有公共函数
  - 检查是否有对应的测试用例

- [ ] **关键业务逻辑覆盖**：检查关键业务逻辑是否有测试
  - 识别关键业务逻辑（如 PR 创建、Jira 集成、Git 操作等）
  - 检查是否有对应的测试用例

- [ ] **错误处理覆盖**：检查错误处理逻辑是否有测试
  - 检查错误路径是否有测试
  - 检查错误消息是否正确

**检查方法**：

1. 读取源代码文件，识别公共函数（`pub fn`）
2. 检查测试文件中是否有对应的测试用例
3. 使用代码搜索工具查找测试用例

**示例输出**：

```markdown
#### Git 模块功能覆盖
- ✅ `GitRepo::is_git_repo()` - 有测试
- ✅ `GitBranch::create()` - 有测试
- ❌ `GitBranch::merge()` - 无测试
- ❌ `GitStash::push()` - 无测试
```

#### 1.3 覆盖率评估

**检查项**：

- [ ] **总体覆盖率估算**：估算整体测试覆盖率
- [ ] **核心模块覆盖率**：估算核心模块（Git、Commit、PR 等）的覆盖率
- [ ] **工具模块覆盖率**：估算工具模块的覆盖率
- [ ] **CLI 层覆盖率**：估算 CLI 命令层的覆盖率

**评估标准**：

- 🟢 **良好** (80%+)：覆盖率 >= 80%
- 🟡 **中等** (60-79%)：覆盖率 60-79%
- 🔴 **不足** (< 60%)：覆盖率 < 60%

**检查方法**：

1. 统计有测试的模块数量 vs 总模块数量
2. 统计有测试的函数数量 vs 总函数数量（估算）
3. 根据测试文件数量和测试用例数量估算覆盖率

**示例输出**：

```markdown
### 覆盖率评估
- **总体覆盖率估算**: 🟡 约 50-60%
- **核心模块覆盖率**: 🔴 约 40-50%（Git、Commit 等核心模块缺失）
- **工具模块覆盖率**: 🟡 约 60-70%
- **CLI 层覆盖率**: 🟢 约 75-80%
```

---

### 2. 测试用例合理性检查

#### 2.1 测试工具使用检查

**检查项**：

- [ ] **参数化测试**：检查是否使用 `rstest` 进行参数化测试
  - 查找 `#[rstest]` 标记的测试
  - 检查参数化测试是否合理

- [ ] **断言工具**：检查是否使用 `pretty_assertions` 提供清晰的错误输出
  - 查找 `use pretty_assertions::assert_eq;` 等导入
  - 检查是否在关键测试中使用

- [ ] **快照测试**：检查是否使用 `insta` 进行快照测试
  - 查找 `insta::assert_json_snapshot!` 等调用
  - 检查快照文件是否管理规范

- [ ] **Mock 测试**：检查是否使用 `mockito` 进行 HTTP API Mock 测试
  - 查找 `mockito` 相关代码
  - 检查 Mock 服务器设置是否规范

**检查方法**：

1. 搜索测试文件中的测试工具使用情况
2. 检查测试工具使用是否符合规范（参考 `TESTING_GUIDELINES.md`）

**示例输出**：

```markdown
### 测试工具使用情况
- ✅ **参数化测试**: 使用 `rstest` 进行参数化测试，减少代码重复
- ✅ **断言工具**: 使用 `pretty_assertions` 提供清晰的错误输出
- ✅ **快照测试**: 使用 `insta` 进行快照测试（LLM 响应）
- ✅ **Mock 测试**: 使用 `mockito` 进行 HTTP API Mock 测试
```

#### 2.2 测试结构检查

**检查项**：

- [ ] **AAA 模式**：检查测试是否遵循 Arrange-Act-Assert 模式
  - 检查测试是否有清晰的准备、执行、断言阶段
  - 检查测试结构是否清晰

- [ ] **测试组织**：检查测试组织是否合理
  - 检查是否使用模块分组组织相关测试
  - 检查测试命名是否规范（`test_` 前缀）
  - 检查测试目录结构是否与源代码对应

- [ ] **测试数据管理**：检查测试数据管理是否规范
  - 检查是否使用 `tests/fixtures/` 目录存放测试数据
  - 检查是否使用共享测试工具（`tests/common/`）
  - 检查快照文件是否管理规范

**检查方法**：

1. 读取测试文件，检查测试结构
2. 检查测试命名规范
3. 检查测试数据管理方式

**示例输出**：

```markdown
### 测试结构
- ✅ **AAA 模式**: 大部分测试遵循 Arrange-Act-Assert 模式
- ✅ **模块化组织**: 测试目录结构与源代码对应
- ✅ **共享工具**: `tests/common/` 提供共享测试工具
- ✅ **测试数据**: 使用 `tests/fixtures/` 目录存放测试数据
```

#### 2.3 测试内容检查

**检查项**：

- [ ] **成功路径测试**：检查是否包含成功路径测试
  - 检查主要功能是否有成功路径测试
  - 检查测试是否验证了预期结果

- [ ] **错误路径测试**：检查是否包含错误路径测试
  - 检查是否有错误情况测试（网络错误、文件系统错误、权限错误等）
  - 检查错误消息是否正确

- [ ] **边界条件测试**：检查是否包含边界条件测试
  - 检查是否有空输入/输出测试
  - 检查是否有最大/最小长度测试
  - 检查是否有特殊字符测试
  - 检查是否有 Unicode 字符处理测试

- [ ] **集成测试**：检查是否包含集成测试
  - 检查是否有端到端的工作流测试
  - 检查是否有模块间交互测试

**检查方法**：

1. 读取测试文件，分析测试内容
2. 检查测试是否覆盖成功路径、错误路径、边界条件
3. 检查是否有集成测试文件

**示例输出**：

```markdown
### 测试内容合理性
#### 正面示例
1. **参数解析测试**: CLI 命令的参数解析测试完整
2. **边界条件测试**: 部分测试包含边界条件
3. **错误处理测试**: 部分测试包含错误情况
4. **集成测试**: 有端到端的工作流测试

#### 需要改进的地方
1. **错误路径测试不足**: 部分测试主要关注成功路径，错误处理测试较少
2. **边界条件测试不完整**: 某些模块缺少边界条件测试
3. **并发测试缺失**: 虽然有并发执行器，但缺少并发场景测试
```

---

### 3. 缺失测试用例检查

#### 3.1 缺失模块测试识别

**检查项**：

- [ ] **完全缺失的模块**：识别完全没有测试的模块
  - 列出所有没有测试文件的模块
  - 列出所有没有单元测试的模块

- [ ] **测试文件为空的模块**：识别测试文件存在但为空的模块
  - 检查测试文件是否只包含注释
  - 检查测试文件是否没有实际测试代码

- [ ] **部分子模块缺失测试**：识别部分子模块缺少测试的情况
  - 检查模块的主要子模块是否有测试
  - 检查关键功能是否有测试

**检查方法**：

1. 对比源代码模块列表和测试文件列表
2. 检查测试文件内容，识别空文件
3. 检查模块的子模块测试覆盖情况

**示例输出**：

```markdown
### 缺失模块测试
#### 完全缺失的模块 ❌
- ❌ **Template 模块** (`lib/template/`)
  - 无测试文件
  - 缺少测试的子模块:
    - `template/config.rs` - 模板配置
    - `template/engine.rs` - 模板引擎
    - `template/vars.rs` - 模板变量

#### 测试文件为空的模块 ⚠️
- ⚠️ **Git 模块** (`lib/git/`)
  - 测试文件存在但为空: `tests/git/mod.rs` 只有注释，没有实际测试
  - 缺少测试的子模块:
    - `git/branch.rs` - 分支管理操作
    - `git/commit.rs` - 提交管理
```

#### 3.2 缺失功能测试识别

**检查项**：

- [ ] **主要功能缺失测试**：识别主要功能缺少测试的情况
  - 列出每个模块的主要功能
  - 检查是否有对应的测试用例

- [ ] **公共函数缺失测试**：识别公共函数缺少测试的情况
  - 列出所有公共函数
  - 检查是否有对应的测试用例

- [ ] **关键业务逻辑缺失测试**：识别关键业务逻辑缺少测试的情况
  - 识别关键业务逻辑（如 PR 创建、Jira 集成、Git 操作等）
  - 检查是否有对应的测试用例

**检查方法**：

1. 读取源代码文件，识别主要功能和公共函数
2. 检查测试文件中是否有对应的测试用例
3. 使用代码搜索工具查找测试用例

**示例输出**：

```markdown
### 缺失功能测试
#### Git 模块 (`lib/git/`)
需要添加的测试：
1. **分支管理** (`git/branch.rs`)
   - 创建分支
   - 切换分支
   - 合并分支（不同策略）
   - 删除分支
   - 获取默认分支
   - 分支存在性检查

2. **提交管理** (`git/commit.rs`)
   - 提交状态检查
   - 暂存文件
   - 创建提交
   - 获取提交信息
   - Worktree 状态检查
```

#### 3.3 缺失测试类型识别

**检查项**：

- [ ] **错误路径测试缺失**：识别缺少错误路径测试的情况
  - 检查每个公共函数是否有错误情况测试
  - 检查是否有网络错误、文件系统错误、权限错误等测试

- [ ] **边界条件测试缺失**：识别缺少边界条件测试的情况
  - 检查是否有空输入/输出测试
  - 检查是否有最大/最小长度测试
  - 检查是否有特殊字符测试

- [ ] **集成测试缺失**：识别缺少集成测试的情况
  - 检查是否有端到端的工作流测试
  - 检查是否有模块间交互测试

**检查方法**：

1. 分析现有测试内容，识别缺失的测试类型
2. 检查是否有错误路径测试、边界条件测试、集成测试

**示例输出**：

```markdown
### 缺失测试类型
#### 错误路径测试缺失
- 部分测试主要关注成功路径，错误处理测试较少
- 需要为每个公共函数添加错误情况测试
- 需要测试网络错误、文件系统错误、权限错误等

#### 边界条件测试缺失
- 某些模块缺少边界条件测试
- 需要添加空输入/输出测试
- 需要添加最大/最小长度测试
- 需要添加特殊字符测试
```

---

## 🔍 检查方法

### 自动化检查工具

1. **代码搜索工具**
   - 使用 `grep` 搜索测试文件
   - 使用 `codebase_search` 进行语义搜索
   - 使用 `glob_file_search` 查找测试文件

2. **文件读取工具**
   - 使用 `read_file` 读取测试文件内容
   - 使用 `list_dir` 列出目录结构

3. **统计分析**
   - 统计测试文件数量
   - 统计测试用例数量（估算）
   - 统计模块覆盖情况

### 手动检查项

1. **测试内容分析**
   - 阅读测试代码，分析测试覆盖范围
   - 检查测试是否合理、有效

2. **测试质量评估**
   - 评估测试工具使用是否规范
   - 评估测试结构是否合理
   - 评估测试内容是否完整

---

## 📊 检查报告格式

检查报告应包含以下部分：

### 1. 执行摘要

- 总体情况（测试文件数、测试用例数、覆盖率评估）
- 主要发现（优点、问题、改进建议）

### 2. 测试覆盖情况分析

- 已覆盖的模块
- 部分覆盖的模块
- 完全缺失的模块
- 覆盖率统计表

### 3. 测试用例合理性分析

- 测试工具使用情况
- 测试结构合理性
- 测试内容合理性
- 测试命名规范

### 4. 缺失的测试用例

- 高优先级缺失测试（核心模块）
- 中优先级缺失测试（工具模块）
- 低优先级缺失测试（命令层补充）

### 5. 测试质量改进建议

- 测试覆盖改进建议
- 测试组织改进建议
- 测试工具改进建议

### 6. 优先级行动计划

- 阶段 1: 核心模块测试（高优先级）
- 阶段 2: 工具模块测试（中优先级）
- 阶段 3: Commands 层测试补充（低优先级）
- 阶段 4: 测试质量提升（持续改进）

### 7. 结论

- 总体评估
- 主要问题
- 改进建议

**参考示例**：`report/TEST_COVERAGE_REPORT.md`

---

## 📚 参考文档

- [测试规范指南](../TESTING_GUIDELINES.md) - 测试组织规范和最佳实践
- [开发规范指南](../DEVELOPMENT_GUIDELINES.md) - 包含测试规范的基础内容
- [提交前检查指南](../PRE_COMMIT_GUIDELINES.md) - 包含测试用例检查的简要说明

---

**最后更新**: 2025-12-16
