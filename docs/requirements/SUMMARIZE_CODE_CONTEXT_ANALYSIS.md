# Summarize åŠŸèƒ½ä¸­ä»£ç ä¸Šä¸‹æ–‡è·å–åˆ†æ

## ğŸ“‹ é—®é¢˜åˆ†æ

### å½“å‰æƒ…å†µ

**ç°æœ‰çš„ summarize åŠŸèƒ½**ï¼š
- åªä½¿ç”¨ PR diffï¼ˆæœ€å¤š 15000 å­—ç¬¦ï¼‰
- LLM åŸºäº diff å†…å®¹ç”Ÿæˆæ€»ç»“å’Œæµ‹è¯•è®¡åˆ’
- å¯¹äºå¤§å‹ PR æˆ–å¤æ‚ä¿®æ”¹ï¼Œå¯èƒ½ç¼ºå°‘è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡

### é—®é¢˜

1. **æ¥å£å®šä¹‰ä¸å®Œæ•´**ï¼š
   - PR diff å¯èƒ½åªæ˜¾ç¤ºæ¥å£çš„éƒ¨åˆ†ä¿®æ”¹
   - ç¼ºå°‘å®Œæ•´çš„å‚æ•°å®šä¹‰ã€å“åº”ç»“æ„
   - ç¼ºå°‘ç›¸å…³çš„ç±»å‹å®šä¹‰ã€éªŒè¯è§„åˆ™

2. **è°ƒç”¨ç‚¹ä¿¡æ¯ç¼ºå¤±**ï¼š
   - ä¸çŸ¥é“æ¥å£åœ¨å“ªé‡Œè¢«è°ƒç”¨
   - ä¸çŸ¥é“å‰ç«¯å¦‚ä½•è°ƒç”¨è¿™ä¸ªæ¥å£
   - ä¸çŸ¥é“å…¶ä»–æœåŠ¡å¦‚ä½•ä¾èµ–è¿™ä¸ªæ¥å£

3. **æµ‹è¯•æ–‡ä»¶ä¿¡æ¯ç¼ºå¤±**ï¼š
   - ä¸çŸ¥é“æ˜¯å¦å·²æœ‰æµ‹è¯•æ–‡ä»¶
   - ä¸çŸ¥é“æµ‹è¯•çš„è¦†ç›–æƒ…å†µ
   - ä¸çŸ¥é“æµ‹è¯•çš„æœ€ä½³å®è·µ

4. **ç›¸å…³ä»£ç ç¼ºå¤±**ï¼š
   - ç¼ºå°‘ç›¸å…³çš„ Service å±‚ä»£ç 
   - ç¼ºå°‘ç›¸å…³çš„ Model/Entity å®šä¹‰
   - ç¼ºå°‘ç›¸å…³çš„é…ç½®æˆ–ä¾èµ–

## ğŸ¯ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆä¸€ï¼šæ™ºèƒ½ä»£ç æœç´¢ + ä¸Šä¸‹æ–‡å¢å¼ºï¼ˆæ¨èï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šä» PR diff ä¸­è¯†åˆ«å…³é”®ä¿¡æ¯ï¼Œç„¶ååœ¨ä»£ç åº“ä¸­æœç´¢ç›¸å…³ä»£ç ï¼Œå°†é¢å¤–çš„ä¸Šä¸‹æ–‡æ·»åŠ åˆ° LLM prompt ä¸­ã€‚

#### å·¥ä½œæµç¨‹

```
1. è§£æ PR diff
   â†“
2. è¯†åˆ«å…³é”®ä¿¡æ¯ï¼ˆæ¥å£è·¯å¾„ã€å‡½æ•°åã€ç»„ä»¶åç­‰ï¼‰
   â†“
3. åœ¨ä»£ç åº“ä¸­æœç´¢ç›¸å…³ä»£ç 
   - æœç´¢æ¥å£å®šä¹‰
   - æœç´¢è°ƒç”¨ç‚¹
   - æœç´¢æµ‹è¯•æ–‡ä»¶
   - æœç´¢ç›¸å…³ç±»å‹å®šä¹‰
   â†“
4. æå–ç›¸å…³ä»£ç ç‰‡æ®µ
   â†“
5. å°†é¢å¤–ä¸Šä¸‹æ–‡æ·»åŠ åˆ° LLM prompt
```

#### å®ç°æ­¥éª¤

**æ­¥éª¤ 1ï¼šä» PR diff è¯†åˆ«å…³é”®ä¿¡æ¯**

```rust
// è¯†åˆ«æ¥å£è·¯å¾„å’Œæ–¹æ³•
fn identify_endpoints(diff: &str) -> Vec<EndpointInfo> {
    // ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æˆ– LLM è¯†åˆ«
    // ä¾‹å¦‚ï¼šPOST /api/users, GET /api/users/:id
}

// è¯†åˆ«å‡½æ•°å
fn identify_functions(diff: &str) -> Vec<String> {
    // ä¾‹å¦‚ï¼šcreateUser, getUserById
}

// è¯†åˆ«ç»„ä»¶å
fn identify_components(diff: &str) -> Vec<String> {
    // ä¾‹å¦‚ï¼šUserCreate, UserDetail
}
```

**æ­¥éª¤ 2ï¼šåœ¨ä»£ç åº“ä¸­æœç´¢ç›¸å…³ä»£ç **

```rust
use std::process::Command;

// æœç´¢æ¥å£å®šä¹‰
fn search_endpoint_definition(endpoint: &EndpointInfo) -> Result<String> {
    // ä½¿ç”¨ git grep æœç´¢æ¥å£è·¯å¾„
    let output = Command::new("git")
        .args(&["grep", "-n", "-A", "20", &endpoint.path])
        .output()?;

    // è§£æè¾“å‡ºï¼Œæå–æ¥å£å®šä¹‰ä»£ç 
    parse_git_grep_output(&output.stdout)
}

// æœç´¢è°ƒç”¨ç‚¹
fn search_call_sites(function_name: &str) -> Result<Vec<String>> {
    // ä½¿ç”¨ git grep æœç´¢å‡½æ•°è°ƒç”¨
    let output = Command::new("git")
        .args(&["grep", "-n", function_name])
        .output()?;

    parse_git_grep_output(&output.stdout)
}

// æœç´¢æµ‹è¯•æ–‡ä»¶
fn search_test_files(file_path: &str) -> Result<Vec<String>> {
    // æŸ¥æ‰¾å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶
    // ä¾‹å¦‚ï¼šsrc/api/users.rs -> tests/api/users_test.rs
    let test_file = infer_test_file_path(file_path);

    if test_file_exists(&test_file) {
        read_file_content(&test_file)
    } else {
        Ok(Vec::new())
    }
}
```

**æ­¥éª¤ 3ï¼šæå–ç›¸å…³ä»£ç ç‰‡æ®µ**

```rust
// æå–æ¥å£çš„å®Œæ•´å®šä¹‰
fn extract_endpoint_definition(code: &str, endpoint: &EndpointInfo) -> String {
    // æå–å‡½æ•°ç­¾åã€å‚æ•°å®šä¹‰ã€å“åº”ç±»å‹ç­‰
    // é™åˆ¶é•¿åº¦ï¼Œé¿å… token è¿‡å¤š
}

// æå–ç›¸å…³çš„ç±»å‹å®šä¹‰
fn extract_type_definitions(code: &str, types: &[String]) -> String {
    // æå– structã€enumã€interface ç­‰ç±»å‹å®šä¹‰
}
```

**æ­¥éª¤ 4ï¼šæ„å»ºå¢å¼ºçš„ LLM prompt**

```rust
fn build_enhanced_prompt(
    pr_title: &str,
    pr_diff: &str,
    additional_context: &AdditionalContext,
) -> String {
    let mut parts = vec![
        format!("PR Title: {}", pr_title),
        format!("PR Diff:\n{}", pr_diff),
    ];

    // æ·»åŠ æ¥å£å®šä¹‰
    if !additional_context.endpoint_definitions.is_empty() {
        parts.push("## Endpoint Definitions".to_string());
        for (endpoint, definition) in &additional_context.endpoint_definitions {
            parts.push(format!("### {}\n```\n{}\n```", endpoint, definition));
        }
    }

    // æ·»åŠ è°ƒç”¨ç‚¹ä¿¡æ¯
    if !additional_context.call_sites.is_empty() {
        parts.push("## Call Sites".to_string());
        for call_site in &additional_context.call_sites {
            parts.push(format!("- {}", call_site));
        }
    }

    // æ·»åŠ æµ‹è¯•æ–‡ä»¶ä¿¡æ¯
    if !additional_context.test_files.is_empty() {
        parts.push("## Existing Test Files".to_string());
        for test_file in &additional_context.test_files {
            parts.push(format!("- {}", test_file));
        }
    }

    parts.join("\n\n")
}
```

### æ–¹æ¡ˆäºŒï¼šåˆ†é˜¶æ®µ LLM è°ƒç”¨

**æ ¸å¿ƒæ€æƒ³**ï¼šå…ˆä½¿ç”¨ LLM è¯†åˆ«éœ€è¦ä»€ä¹ˆä¸Šä¸‹æ–‡ï¼Œç„¶åå†è·å–ç›¸å…³ä»£ç ã€‚

#### å·¥ä½œæµç¨‹

```
1. ç¬¬ä¸€æ¬¡ LLM è°ƒç”¨ï¼šåˆ†æ PR diffï¼Œè¯†åˆ«éœ€è¦çš„ä¿¡æ¯
   - éœ€è¦å“ªäº›æ¥å£çš„å®Œæ•´å®šä¹‰ï¼Ÿ
   - éœ€è¦å“ªäº›å‡½æ•°çš„è°ƒç”¨ç‚¹ï¼Ÿ
   - éœ€è¦å“ªäº›ç›¸å…³çš„ç±»å‹å®šä¹‰ï¼Ÿ
   â†“
2. æ ¹æ® LLM çš„å»ºè®®ï¼Œåœ¨ä»£ç åº“ä¸­æœç´¢ç›¸å…³ä»£ç 
   â†“
3. ç¬¬äºŒæ¬¡ LLM è°ƒç”¨ï¼šä½¿ç”¨å®Œæ•´çš„ä¸Šä¸‹æ–‡ç”Ÿæˆæµ‹è¯•è®¡åˆ’
```

**ä¼˜ç‚¹**ï¼š
- LLM å¯ä»¥æ™ºèƒ½åœ°å†³å®šéœ€è¦ä»€ä¹ˆä¸Šä¸‹æ–‡
- é¿å…è·å–ä¸å¿…è¦çš„ä»£ç 
- æ›´çµæ´»

**ç¼ºç‚¹**ï¼š
- éœ€è¦ä¸¤æ¬¡ LLM è°ƒç”¨ï¼Œæˆæœ¬æ›´é«˜
- å®ç°æ›´å¤æ‚

### æ–¹æ¡ˆä¸‰ï¼šé…ç½®åŒ–çš„ä¸Šä¸‹æ–‡è·å–

**æ ¸å¿ƒæ€æƒ³**ï¼šå…è®¸ç”¨æˆ·é…ç½®éœ€è¦è·å–å“ªäº›ç±»å‹çš„ä¸Šä¸‹æ–‡ã€‚

#### é…ç½®ç¤ºä¾‹

```toml
[summarize.context]
# æ˜¯å¦è·å–æ¥å£å®šä¹‰
fetch_endpoint_definitions = true

# æ˜¯å¦è·å–è°ƒç”¨ç‚¹
fetch_call_sites = true

# æ˜¯å¦è·å–æµ‹è¯•æ–‡ä»¶
fetch_test_files = true

# æ˜¯å¦è·å–ç›¸å…³ç±»å‹å®šä¹‰
fetch_type_definitions = true

# æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆå­—ç¬¦ï¼‰
max_context_length = 10000

# æ¯ä¸ªæ¥å£çš„æœ€å¤§ä»£ç è¡Œæ•°
max_lines_per_endpoint = 50
```

## ğŸ“Š æ¨èçš„å®ç°æ–¹æ¡ˆ

### MVP ç‰ˆæœ¬ï¼ˆæœ€å°å¯è¡Œäº§å“ï¼‰

**é‡‡ç”¨æ–¹æ¡ˆä¸€ï¼Œä½†ç®€åŒ–å®ç°**ï¼š

1. **åªè·å–æ¥å£å®šä¹‰**ï¼š
   - ä» PR diff è¯†åˆ«æ¥å£è·¯å¾„
   - ä½¿ç”¨ `git grep` æœç´¢æ¥å£å®šä¹‰
   - æå–æ¥å£çš„å®Œæ•´ä»£ç ï¼ˆé™åˆ¶é•¿åº¦ï¼‰

2. **ä¸è·å–è°ƒç”¨ç‚¹**ï¼ˆåç»­ç‰ˆæœ¬æ”¯æŒï¼‰

3. **ä¸è·å–æµ‹è¯•æ–‡ä»¶**ï¼ˆåç»­ç‰ˆæœ¬æ”¯æŒï¼‰

**å®ç°å¤æ‚åº¦**ï¼šä½
**å¼€å‘æ—¶é—´**ï¼š1-2 å¤©

### å®Œæ•´ç‰ˆæœ¬

**é‡‡ç”¨æ–¹æ¡ˆä¸€ï¼Œå®Œæ•´å®ç°**ï¼š

1. **è·å–æ¥å£å®šä¹‰**
2. **è·å–è°ƒç”¨ç‚¹**ï¼ˆå‰ç«¯è°ƒç”¨ã€å…¶ä»–æœåŠ¡è°ƒç”¨ï¼‰
3. **è·å–æµ‹è¯•æ–‡ä»¶**ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
4. **è·å–ç›¸å…³ç±»å‹å®šä¹‰**

**å®ç°å¤æ‚åº¦**ï¼šä¸­
**å¼€å‘æ—¶é—´**ï¼š3-5 å¤©

## ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚

### 1. æ¥å£è¯†åˆ«

**ä» PR diff ä¸­è¯†åˆ«æ¥å£**ï¼š

```rust
// ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¯†åˆ«å¸¸è§æ¨¡å¼
fn identify_endpoints_from_diff(diff: &str) -> Vec<EndpointInfo> {
    let mut endpoints = Vec::new();

    // Rust: #[post("/api/users")]
    let rust_pattern = Regex::new(r#"#\[(get|post|put|delete|patch)\(["']([^"']+)["']\)\]"#)?;

    // Spring Boot: @PostMapping("/api/users")
    let spring_pattern = Regex::new(r#"@(Get|Post|Put|Delete|Patch)Mapping\(["']([^"']+)["']\)"#)?;

    // Express: router.post('/api/users')
    let express_pattern = Regex::new(r#"router\.(get|post|put|delete|patch)\(["']([^"']+)["']"#)?;

    // åœ¨ diff ä¸­æœç´¢è¿™äº›æ¨¡å¼
    // ...

    endpoints
}
```

### 2. ä»£ç æœç´¢

**ä½¿ç”¨ Git å‘½ä»¤æœç´¢**ï¼š

```rust
use std::process::Command;

fn search_codebase(pattern: &str, context_lines: usize) -> Result<String> {
    let output = Command::new("git")
        .args(&[
            "grep",
            "-n",
            "-A", &context_lines.to_string(),
            "-B", "5",  // å‰ 5 è¡Œä¸Šä¸‹æ–‡
            pattern,
        ])
        .output()?;

    Ok(String::from_utf8(output.stdout)?)
}
```

### 3. ä»£ç æå–å’Œé™åˆ¶

**æå–ç›¸å…³ä»£ç ç‰‡æ®µï¼Œé™åˆ¶é•¿åº¦**ï¼š

```rust
fn extract_relevant_code(
    code: &str,
    target_line: usize,
    max_lines: usize,
) -> String {
    let lines: Vec<&str> = code.lines().collect();
    let start = target_line.saturating_sub(10);  // å‰ 10 è¡Œ
    let end = (target_line + max_lines).min(lines.len());

    lines[start..end].join("\n")
}
```

### 4. ä¸Šä¸‹æ–‡ç®¡ç†

**ç®¡ç†ä¸Šä¸‹æ–‡ï¼Œé¿å… token è¿‡å¤š**ï¼š

```rust
struct AdditionalContext {
    endpoint_definitions: Vec<(String, String)>,  // (endpoint, code)
    call_sites: Vec<String>,
    test_files: Vec<String>,
    max_total_length: usize,
}

impl AdditionalContext {
    fn add_endpoint_definition(&mut self, endpoint: String, code: String) {
        // æ£€æŸ¥æ€»é•¿åº¦
        let current_length: usize = self.endpoint_definitions
            .iter()
            .map(|(_, code)| code.len())
            .sum();

        if current_length + code.len() <= self.max_total_length {
            self.endpoint_definitions.push((endpoint, code));
        }
    }
}
```

## ğŸ“ Prompt å¢å¼º

### åœ¨ `summarize_pr.system.rs` ä¸­è¯´æ˜å¦‚ä½•ä½¿ç”¨é¢å¤–ä¸Šä¸‹æ–‡

```rust
// åœ¨ prompt ä¸­æ·»åŠ è¯´æ˜
r#"
## Additional Context

If additional code context is provided (endpoint definitions, call sites, etc.),
use this information to generate more detailed and accurate test plans:

- **Endpoint Definitions**: Use the complete endpoint definitions to understand:
  - All parameters (path, query, body)
  - Parameter types and validation rules
  - Response structures
  - Authentication requirements

- **Call Sites**: Use call site information to understand:
  - How the endpoint is used in the codebase
  - What data is typically passed
  - What errors might occur

- **Test Files**: If existing test files are provided, use them to understand:
  - Current test coverage
  - Testing patterns used in the project
  - Test data structures

Generate test plans based on both the PR diff and the additional context provided.
"#
```

### åœ¨ `summarize_user_prompt` ä¸­æ·»åŠ é¢å¤–ä¸Šä¸‹æ–‡

```rust
fn summarize_user_prompt(
    pr_title: &str,
    pr_diff: &str,
    additional_context: Option<&AdditionalContext>,
) -> String {
    let mut parts = vec![
        format!("PR Title: {}", pr_title),
        format!("PR Diff:\n{}", pr_diff),
    ];

    if let Some(ctx) = additional_context {
        if !ctx.endpoint_definitions.is_empty() {
            parts.push("## Additional Context: Endpoint Definitions".to_string());
            for (endpoint, code) in &ctx.endpoint_definitions {
                parts.push(format!("### {}\n```rust\n{}\n```", endpoint, code));
            }
        }

        // æ·»åŠ å…¶ä»–ä¸Šä¸‹æ–‡...
    }

    parts.join("\n\n")
}
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. Token é™åˆ¶

- LLM æœ‰ token é™åˆ¶ï¼ˆé€šå¸¸ 4K-128Kï¼‰
- éœ€è¦é™åˆ¶é¢å¤–ä¸Šä¸‹æ–‡çš„é•¿åº¦
- å»ºè®®ï¼šé¢å¤–ä¸Šä¸‹æ–‡ä¸è¶…è¿‡ 5000-10000 å­—ç¬¦

### 2. æ€§èƒ½è€ƒè™‘

- Git å‘½ä»¤æœç´¢å¯èƒ½è¾ƒæ…¢ï¼ˆå¤§å‹ä»£ç åº“ï¼‰
- å»ºè®®ï¼šå¹¶è¡Œæœç´¢å¤šä¸ªæ¥å£
- å»ºè®®ï¼šç¼“å­˜æœç´¢ç»“æœ

### 3. å‡†ç¡®æ€§

- ä»£ç æœç´¢å¯èƒ½è¿”å›ä¸ç›¸å…³çš„ç»“æœ
- éœ€è¦è¿‡æ»¤å’ŒéªŒè¯æœç´¢ç»“æœ
- å»ºè®®ï¼šä½¿ç”¨æ›´ç²¾ç¡®çš„æœç´¢æ¨¡å¼

### 4. å¯é€‰æ€§

- é¢å¤–ä¸Šä¸‹æ–‡åº”è¯¥æ˜¯å¯é€‰çš„
- å¦‚æœæœç´¢å¤±è´¥ï¼Œåº”è¯¥å›é€€åˆ°åªä½¿ç”¨ PR diff
- å»ºè®®ï¼šæ·»åŠ é…ç½®é¡¹æ§åˆ¶æ˜¯å¦å¯ç”¨

## âœ… å®æ–½å»ºè®®

### é˜¶æ®µä¸€ï¼šMVPï¼ˆå½“å‰é˜¶æ®µï¼‰

1. **åªå¢å¼º Prompt**ï¼š
   - ä¿®æ”¹ `summarize_pr.system.rs`ï¼Œè¯´æ˜å¦‚ä½•ä½¿ç”¨é¢å¤–ä¸Šä¸‹æ–‡
   - ä½†ä¸å®é™…è·å–é¢å¤–ä¸Šä¸‹æ–‡
   - è®© LLM åŸºäºç°æœ‰ PR diff ç”Ÿæˆæµ‹è¯•è®¡åˆ’

2. **æµ‹è¯•éªŒè¯**ï¼š
   - ä½¿ç”¨å‡ ä¸ªçœŸå®çš„ PR æµ‹è¯•
   - éªŒè¯è¾“å‡ºè´¨é‡

### é˜¶æ®µäºŒï¼šåŸºç¡€ä¸Šä¸‹æ–‡è·å–

1. **å®ç°æ¥å£è¯†åˆ«**ï¼š
   - ä» PR diff è¯†åˆ«æ¥å£è·¯å¾„å’Œæ–¹æ³•
   - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¸¸è§æ¨¡å¼

2. **å®ç°ä»£ç æœç´¢**ï¼š
   - ä½¿ç”¨ `git grep` æœç´¢æ¥å£å®šä¹‰
   - æå–æ¥å£çš„å®Œæ•´ä»£ç ï¼ˆé™åˆ¶é•¿åº¦ï¼‰

3. **é›†æˆåˆ° summarize**ï¼š
   - åœ¨ `summarize` å‡½æ•°ä¸­è°ƒç”¨ä»£ç æœç´¢
   - å°†é¢å¤–ä¸Šä¸‹æ–‡æ·»åŠ åˆ° LLM prompt

### é˜¶æ®µä¸‰ï¼šå®Œæ•´ä¸Šä¸‹æ–‡è·å–

1. **è·å–è°ƒç”¨ç‚¹**
2. **è·å–æµ‹è¯•æ–‡ä»¶**
3. **è·å–ç›¸å…³ç±»å‹å®šä¹‰**
4. **ä¼˜åŒ–æ€§èƒ½å’Œå‡†ç¡®æ€§**

## ğŸ“š å‚è€ƒ

- ä»£ç åº“è®¿é—®ç­–ç•¥ï¼š`docs/requirements/CODEBASE_ACCESS_STRATEGY.md`
- PR æµ‹è¯•æ–¹æ¡ˆåˆ†æï¼š`docs/requirements/PR_TEST_SCHEME_ANALYSIS.md`
- Summarize æµ‹è¯•æ­¥éª¤åˆ†æï¼š`docs/requirements/SUMMARIZE_TEST_STEP_ANALYSIS.md`

