//! æœç´¢æ¨¡å—
//! åœ¨æ—¥å¿—æ–‡ä»¶ä¸­æœç´¢å…³é”®è¯

use anyhow::{Context, Result};
use regex::Regex;
use std::collections::HashSet;
use std::io::BufRead;
use std::path::Path;
use std::sync::OnceLock;

use super::extract::extract_url_from_line;
use super::parse::{add_entry_if_not_duplicate, parse_log_entry, LogEntry};
use super::utils::open_log_file;

/// åœ¨æ—¥å¿—æ–‡ä»¶ä¸­æœç´¢å…³é”®è¯
/// è¿”å›åŒ¹é…çš„è¯·æ±‚ä¿¡æ¯åˆ—è¡¨ï¼ˆURL å’Œ IDï¼‰
///
/// æ”¯æŒä¸¤ç§æ—¥å¿—æ ¼å¼ï¼š
/// 1. flutter-api.log æ ¼å¼ï¼šä»¥ ğŸ’¡ å¼€å¤´çš„è¡Œ
/// 2. api.log æ ¼å¼ï¼šåŒ…å« `#<æ•°å­—> <HTTPæ–¹æ³•> <URL>` çš„è¡Œ
///
/// åŒ¹é… shell è„šæœ¬ qksearch.sh çš„é€»è¾‘ï¼š
/// 1. æŸ¥æ‰¾æ–°æ—¥å¿—æ¡ç›®ï¼ˆğŸ’¡ å¼€å¤´æˆ–åŒ…å« `#<æ•°å­—> <HTTPæ–¹æ³•>` çš„è¡Œï¼‰
/// 2. æå– IDï¼ˆ#<æ•°å­—>ï¼‰å’Œ URL
/// 3. åœ¨å½“å‰å—ä¸­æœç´¢å…³é”®è¯ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ï¼ŒåŒ…æ‹¬æ¡ç›®è¡Œæœ¬èº«
/// 4. å¦‚æœæ‰¾åˆ°åŒ¹é…ï¼Œè®°å½•è¯¥å—çš„ URL å’Œ ID
/// 5. ç©ºè¡Œè¡¨ç¤ºå—ç»“æŸ
pub fn search_keyword(log_file: &Path, keyword: &str) -> Result<Vec<LogEntry>> {
    let reader = open_log_file(log_file)?;
    let keyword_lower = keyword.to_lowercase();
    let mut results = Vec::new();
    let mut printed_ids = HashSet::new();
    let mut current_entry: Option<LogEntry> = None;
    let mut found_in_current_block = false;

    // ç”¨äºæ£€æµ‹ api.log æ ¼å¼çš„æ¡ç›®ï¼ˆåŒ…å« `#<æ•°å­—> <HTTPæ–¹æ³•>` çš„æ¨¡å¼ï¼‰
    // ä½¿ç”¨é™æ€æ­£åˆ™è¡¨è¾¾å¼é¿å…é‡å¤ç¼–è¯‘
    static API_LOG_ENTRY_PATTERN: OnceLock<Option<Regex>> = OnceLock::new();
    let api_log_entry_pattern = API_LOG_ENTRY_PATTERN
        .get_or_init(|| Regex::new(r"#\d+\s+(GET|POST|PUT|DELETE|PATCH|HEAD|OPTIONS)").ok());

    for line_result in reader.lines() {
        let line = line_result.context("Failed to read line")?;
        let line_lower = line.to_lowercase();

        // æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ¡ç›®çš„å¼€å§‹
        let is_new_entry = if line.starts_with("ğŸ’¡") {
            // flutter-api.log æ ¼å¼ï¼šä»¥ ğŸ’¡ å¼€å¤´
            true
        } else if let Some(pattern) = api_log_entry_pattern.as_ref() {
            // api.log æ ¼å¼ï¼šåŒ…å« `#<æ•°å­—> <HTTPæ–¹æ³•>` çš„æ¨¡å¼
            pattern.is_match(&line)
        } else {
            false
        };

        if is_new_entry {
            // å¦‚æœä¹‹å‰çš„æ¡ç›®åŒ¹é…ï¼Œä¿å­˜å®ƒï¼ˆé¿å…é‡å¤ï¼‰
            if found_in_current_block {
                add_entry_if_not_duplicate(current_entry.take(), &mut results, &mut printed_ids);
            }

            // è§£ææ–°æ¡ç›®
            current_entry = parse_log_entry(&line)?;
            // åœ¨æ¡ç›®è¡Œæœ¬èº«ä¹Ÿæœç´¢å…³é”®è¯ï¼ˆå› ä¸º URL é€šå¸¸åœ¨è¿™ä¸€è¡Œï¼‰
            found_in_current_block = line_lower.contains(&keyword_lower);
        } else if current_entry.is_some() {
            // åœ¨å½“å‰å—ä¸­æœç´¢å…³é”®è¯ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            if line_lower.contains(&keyword_lower) {
                found_in_current_block = true;
            }

            // æå– URLï¼ˆå¦‚æœéœ€è¦ï¼‰
            if let Some(ref mut entry) = current_entry {
                if entry.url.is_none() {
                    entry.url = extract_url_from_line(&line);
                }
            }
        }

        // ç©ºè¡Œè¡¨ç¤ºå—ç»“æŸ
        if line.trim().is_empty() {
            // å¦‚æœå½“å‰å—åŒ¹é…ï¼Œä¿å­˜ç»“æœ
            if found_in_current_block {
                add_entry_if_not_duplicate(current_entry.take(), &mut results, &mut printed_ids);
            }
            // é‡ç½®çŠ¶æ€
            current_entry = None;
            found_in_current_block = false;
        }
    }

    // æ£€æŸ¥æœ€åä¸€ä¸ªæ¡ç›®
    if found_in_current_block {
        add_entry_if_not_duplicate(current_entry, &mut results, &mut printed_ids);
    }

    Ok(results)
}
